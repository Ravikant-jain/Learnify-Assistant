{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import google.generativeai as genai\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poop(context):\n",
    "    poompt = '''\n",
    "Can you give me 10 quiz questions based on {}, i want it in specific json file format, like -   \n",
    "[\n",
    "    {{\n",
    "        \"question\": \"(Question)\",\n",
    "        \"options\": ([\"option1\", \"option2\", \"option3\", \"option4\"]),\n",
    "        \"answer\": \"(answer here)\"\n",
    "    }},\n",
    "    {{\n",
    "        \"question\": \"What is 2 + 2?\",\n",
    "        \"options\": [\"3\", \"4\", \"5\", \"6\"],\n",
    "        \"answer\": \"B\"\n",
    "    }},\n",
    "    {{\n",
    "        \"question\": \"What is the largest planet in our solar system?\",\n",
    "        \"options\": [\"Earth\", \"Venus\", \"Jupiter\", \"Mars\"],\n",
    "        \"answer\": \"C\"\n",
    "    }}\n",
    "]\n",
    "'''.format(context)\n",
    "    return poompt\n",
    "\n",
    "# poompt = poop('hey')\n",
    "# print(poompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro=poop('chapter 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCan you give me 10 quiz questions based on chapter 1, i want it in specific json file format, like -   \\n[\\n    {\\n        \"question\": \"(Question)\",\\n        \"options\": ([\"option1\", \"option2\", \"option3\", \"option4\"]),\\n        \"answer\": \"(answer here)\"\\n    },\\n    {\\n        \"question\": \"What is 2 + 2?\",\\n        \"options\": [\"3\", \"4\", \"5\", \"6\"],\\n        \"answer\": \"B\"\\n    },\\n    {\\n        \"question\": \"What is the largest planet in our solar system?\",\\n        \"options\": [\"Earth\", \"Venus\", \"Jupiter\", \"Mars\"],\\n        \"answer\": \"C\"\\n    }\\n]\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“\n"
     ]
    }
   ],
   "source": [
    "icon=\"ðŸ“\"\n",
    "print((icon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error in __cdecl faiss::FileIOReader::FileIOReader(const char *) at D:\\a\\faiss-wheels\\faiss-wheels\\faiss\\faiss\\impl\\io.cpp:68: Error: 'f' failed: could not open faiss_index\\index.faiss for reading: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21872\\1702760537.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpdf_chat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcon_for_ques\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mque_p\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcon_for_ques\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpro\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mque_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Github\\Edu-AiX\\AI\\pdf_chat.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(usr)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcon_for_ques\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGoogleGenerativeAIEmbeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"models/embedding-001\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0mnew_db\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"D:\\Github\\Edu-AiX\\faiss_index\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_db\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilarity_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mchain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_conversational_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(cls, folder_path, embeddings, index_name, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m         \"\"\"\n\u001b[0;32m   1107\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;31m# load index separately since it is not picklable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m         \u001b[0mfaiss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdependable_faiss_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m         index = faiss.read_index(\n\u001b[0m\u001b[0;32m   1111\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m\"{index_name}.faiss\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         )\n\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python311\\Lib\\site-packages\\faiss\\swigfaiss.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   9794\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9795\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_swigfaiss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Error in __cdecl faiss::FileIOReader::FileIOReader(const char *) at D:\\a\\faiss-wheels\\faiss-wheels\\faiss\\faiss\\impl\\io.cpp:68: Error: 'f' failed: could not open faiss_index\\index.faiss for reading: No such file or directory"
     ]
    }
   ],
   "source": [
    "from pdf_chat import con_for_ques\n",
    "\n",
    "que_p=con_for_ques(pro)\n",
    "que_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "import google.generativeai as genai\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import textwrap\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content('tell me something about history of india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> **Ancient India (c. 3300 BCE - 500 BCE)**\n",
       "> \n",
       "> * Indus Valley Civilization (c. 3300 - 1900 BCE): Flourished in the northwestern part of the Indian subcontinent, with advanced urban centers, a written script, and a sophisticated society.\n",
       "> * Vedic Period (c. 1500 - 500 BCE): Aryans migrated to India and established a society based on the Vedas, a collection of religious hymns and texts.\n",
       "> * Mahajanapadas (c. 600 - 322 BCE): Sixteen major states emerged, including Magadha, which would later become the Mauryan Empire.\n",
       "> \n",
       "> **Classical India (c. 500 BCE - 1200 CE)**\n",
       "> \n",
       "> * **Mauryan Empire (c. 322 - 180 BCE):** Led by Chandragupta Maurya, this empire unified most of the Indian subcontinent and established a centralized government.\n",
       "> * **Gupta Empire (c. 320 - 550 CE):** A golden age of Indian history, characterized by political stability, economic prosperity, and cultural and intellectual achievements.\n",
       "> * **Medieval India (c. 1200 - 1526 CE)**\n",
       "> * **Delhi Sultanate (1206 - 1526 CE):** Founded by the Delhi Mamluks, this Muslim dynasty ruled over much of North India.\n",
       "> * **Bahmani Sultanate (1347 - 1527 CE):** A Deccan-based Muslim dynasty that broke away from the Delhi Sultanate and established a powerful kingdom.\n",
       "> * **Vijayanagara Empire (1336 - 1646 CE):** A Hindu empire in South India that resisted Muslim invasions and flourished in the fields of art, architecture, and literature.\n",
       "> \n",
       "> **Mughal Empire (1526 - 1857 CE)**\n",
       "> \n",
       "> * **Babur (1526 - 1530):** Founded the Mughal Empire after invading India from Central Asia.\n",
       "> * **Akbar (1556 - 1605):** Expanded the empire, introduced reforms, and established a tolerant religious policy.\n",
       "> * **Shah Jahan (1628 - 1658):** Built the Taj Mahal as a mausoleum for his wife, Mumtaz Mahal.\n",
       "> \n",
       "> **British Colonial Period (1757 - 1947)**\n",
       "> \n",
       "> * **East India Company (1757 - 1857):** A British trading company that gradually acquired political power in India.\n",
       "> * **Indian Mutiny (1857 - 1858):** A widespread rebellion against British rule, which resulted in the establishment of direct British colonial rule.\n",
       "> * **Indian National Movement (Late 19th century - 1947):** Led by figures such as Mahatma Gandhi, the movement advocated for Indian independence through nonviolent resistance.\n",
       "> \n",
       "> **Independent India (1947 - Present)**\n",
       "> \n",
       "> * **Partition of India (1947):** British India was partitioned into India and Pakistan, resulting in widespread violence and displacement.\n",
       "> * **Nehru Era (1947 - 1964):** Jawaharlal Nehru became the first Prime Minister of independent India and established a secular and democratic state.\n",
       "> * **Green Revolution (1960s - 1970s):** Agricultural reforms that helped increase food production in India.\n",
       "> * **Economic Liberalization (1991):** Reforms that liberalized the Indian economy and led to rapid economic growth.\n",
       "> * **21st Century:** India continues to face challenges such as poverty, inequality, and communalism, while also making significant progress in areas such as technology, education, and healthcare."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## loading all the environment variables\n",
    "\n",
    "import streamlit as st\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "## function to load Gemini Pro model and get repsonses\n",
    "model=genai.GenerativeModel(\"gemini-pro\") \n",
    "chat = model.start_chat(history=[])\n",
    "def get_gemini_response(question):\n",
    "    \n",
    "    response=chat.send_message(question,stream=True)\n",
    "    return response\n",
    "\n",
    "##initialize our streamlit app\n",
    "\n",
    "st.set_page_config(page_title=\"Q&A Demo\")\n",
    "\n",
    "st.header(\"Gemini LLM Application\")\n",
    "\n",
    "# Initialize session state for chat history if it doesn't exist\n",
    "if 'chat_history' not in st.session_state:\n",
    "    st.session_state['chat_history'] = []\n",
    "\n",
    "input=st.text_input(\"Input: \",key=\"input\")\n",
    "submit=st.button(\"Ask the question\")\n",
    "\n",
    "if submit and input:\n",
    "    response=get_gemini_response(input)\n",
    "    # Add user query and response to session state chat history\n",
    "    st.session_state['chat_history'].append((\"You\", input))\n",
    "    st.subheader(\"The Response is\")\n",
    "    for chunk in response:\n",
    "        st.write(chunk.text)\n",
    "        st.session_state['chat_history'].append((\"Bot\", chunk.text))\n",
    "st.subheader(\"The Chat History is\")\n",
    "    \n",
    "for role, text in st.session_state['chat_history']:\n",
    "    st.write(f\"{role}: {text}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
